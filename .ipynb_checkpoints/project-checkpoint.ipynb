{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2c5d17-c574-4651-a0c8-caf195541449",
   "metadata": {},
   "source": [
    "## Installation et importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8172f-fd03-4067-8e74-a43d74806a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (23.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from scikit-image) (0.4)\n",
      "^C\n",
      "Requirement already satisfied: opencv-python in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: mahotas in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (1.4.18)\n",
      "Requirement already satisfied: numpy in c:\\users\\mehdi\\anaconda3\\lib\\site-packages (from mahotas) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# Installation des bibliothèques nécessaires\n",
    "!pip install scikit-image\n",
    "!pip install opencv-python\n",
    "!pip install mahotas\n",
    "!pip install tqdm\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install joblib\n",
    "\n",
    "# Importation des bibliothèques standard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Bibliothèques pour le traitement d'images\n",
    "from skimage import io, color, filters, feature, morphology\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.feature import local_binary_pattern\n",
    "import mahotas as mh\n",
    "\n",
    "# Bibliothèques pour le ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Pour les visualisations interactives dans Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3582a-9259-4a84-99a5-be72514d25bd",
   "metadata": {},
   "source": [
    "## Vérification des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d6761-0151-4162-a08e-70f91715d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la structure du dossier de données\n",
    "data_path = \"data\"  # Ajustez si votre dossier a un nom différent\n",
    "print(\"Contenu du dossier de données:\")\n",
    "print(os.listdir(data_path))\n",
    "\n",
    "# Afficher le nombre d'images par classe\n",
    "class_counts = {}\n",
    "for class_name in os.listdir(data_path):\n",
    "    class_dir = os.path.join(data_path, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        count = len(glob.glob(os.path.join(class_dir, \"*.jpg\")))\n",
    "        class_counts[class_name] = count\n",
    "        print(f\"Classe '{class_name}': {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d6dce-d04b-4fc9-8ab0-8ac3c9d08e1a",
   "metadata": {},
   "source": [
    "## Fonctions de traitement morphologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503255ff-0698-4dbb-80e9-32dbae13ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image_morphology(image, method='watershed'):\n",
    "    \"\"\"\n",
    "    Segmente l'image en utilisant des techniques morphologiques\n",
    "    \n",
    "    Args:\n",
    "        image: Image d'entrée\n",
    "        method: Méthode de segmentation ('watershed', 'region_growing')\n",
    "    \n",
    "    Returns:\n",
    "        Image segmentée et labels des segments\n",
    "    \"\"\"\n",
    "    # Conversion en niveaux de gris si nécessaire\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Appliquer un flou gaussien pour réduire le bruit\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    if method.lower() == 'watershed':\n",
    "        # Segmentation watershed\n",
    "        # Calcul du gradient pour trouver les bordures\n",
    "        gradient = apply_morphological_operation(blurred, 'gradient', 3)\n",
    "        \n",
    "        # Binarisation du gradient\n",
    "        _, binary = cv2.threshold(gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Transformation de distance\n",
    "        dist = cv2.distanceTransform(binary, cv2.DIST_L2, 3)\n",
    "        \n",
    "        # Binarisation de la transformation de distance\n",
    "        _, dist_bin = cv2.threshold(dist, 0.5*dist.max(), 255, cv2.THRESH_BINARY)\n",
    "        dist_bin = dist_bin.astype(np.uint8)\n",
    "        \n",
    "        # Recherche des marqueurs (noyaux des régions)\n",
    "        contours, _ = cv2.findContours(dist_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        markers = np.zeros_like(gray)\n",
    "        for i, contour in enumerate(contours):\n",
    "            cv2.drawContours(markers, [contour], -1, i+1, -1)\n",
    "        \n",
    "        # Appliquer watershed\n",
    "        if len(image.shape) == 2:\n",
    "            image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            image_color = image.copy()\n",
    "        \n",
    "        markers_copy = markers.copy()\n",
    "        cv2.watershed(image_color, markers_copy)\n",
    "        \n",
    "        return markers_copy, len(contours)\n",
    "    \n",
    "    elif method.lower() == 'region_growing':\n",
    "        # Implémentation simplifiée de croissance de région\n",
    "        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Trouver les composantes connectées\n",
    "        num_labels, labels = cv2.connectedComponents(binary)\n",
    "        \n",
    "        return labels, num_labels - 1\n",
    "    \n",
    "    else:\n",
    "        # Méthode par défaut: simple seuillage adaptatif\n",
    "        binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        num_labels, labels = cv2.connectedComponents(binary)\n",
    "        \n",
    "        return labels, num_labels - 1\n",
    "print(\"Traitement morphologique terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7722057-1086-4bce-b228-c609dc8854ff",
   "metadata": {},
   "source": [
    "## Fonctions de segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184901cd-f9d5-4295-89f1-9369d582983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image_morphology(image, method='watershed'):\n",
    "    \"\"\"\n",
    "    Segmente l'image en utilisant des techniques morphologiques\n",
    "    \n",
    "    Args:\n",
    "        image: Image d'entrée\n",
    "        method: Méthode de segmentation ('watershed', 'region_growing')\n",
    "    \n",
    "    Returns:\n",
    "        Image segmentée et labels des segments\n",
    "    \"\"\"\n",
    "    # Conversion en niveaux de gris si nécessaire\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Appliquer un flou gaussien pour réduire le bruit\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    if method.lower() == 'watershed':\n",
    "        # Segmentation watershed\n",
    "        # Calcul du gradient pour trouver les bordures\n",
    "        gradient = apply_morphological_operation(blurred, 'gradient', 3)\n",
    "        \n",
    "        # Binarisation du gradient\n",
    "        _, binary = cv2.threshold(gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Transformation de distance\n",
    "        dist = cv2.distanceTransform(binary, cv2.DIST_L2, 3)\n",
    "        \n",
    "        # Binarisation de la transformation de distance\n",
    "        _, dist_bin = cv2.threshold(dist, 0.5*dist.max(), 255, cv2.THRESH_BINARY)\n",
    "        dist_bin = dist_bin.astype(np.uint8)\n",
    "        \n",
    "        # Recherche des marqueurs (noyaux des régions)\n",
    "        contours, _ = cv2.findContours(dist_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        markers = np.zeros_like(gray)\n",
    "        for i, contour in enumerate(contours):\n",
    "            cv2.drawContours(markers, [contour], -1, i+1, -1)\n",
    "        \n",
    "        # Appliquer watershed\n",
    "        if len(image.shape) == 2:\n",
    "            image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            image_color = image.copy()\n",
    "        \n",
    "        markers_copy = markers.copy()\n",
    "        cv2.watershed(image_color, markers_copy)\n",
    "        \n",
    "        return markers_copy, len(contours)\n",
    "    \n",
    "    elif method.lower() == 'region_growing':\n",
    "        # Implémentation simplifiée de croissance de région\n",
    "        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Trouver les composantes connectées\n",
    "        num_labels, labels = cv2.connectedComponents(binary)\n",
    "        \n",
    "        return labels, num_labels - 1\n",
    "    \n",
    "    else:\n",
    "        # Méthode par défaut: simple seuillage adaptatif\n",
    "        binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "        \n",
    "        num_labels, labels = cv2.connectedComponents(binary)\n",
    "        \n",
    "        return labels, num_labels - 1\n",
    "print(\"Traitement de segmentation terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657bd834-734d-482c-96a5-e0ad8ba41841",
   "metadata": {},
   "source": [
    "## Extractions des caractéristiques de texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c9013-d337-4d1a-9ee7-4a851e4cecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texture_features(image):\n",
    "    \"\"\"\n",
    "    Extrait les caractéristiques de texture d'une image\n",
    "    \n",
    "    Args:\n",
    "        image: Image en niveaux de gris\n",
    "        \n",
    "    Returns:\n",
    "        Vecteur de caractéristiques\n",
    "    \"\"\"\n",
    "    # Si l'image est en couleur, la convertir en niveaux de gris\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Redimensionner l'image pour normaliser\n",
    "    resized = cv2.resize(gray, (128, 128))\n",
    "    \n",
    "    # Caractéristiques GLCM\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    glcm = graycomatrix(resized, distances, angles, 256, symmetric=True, normed=True)\n",
    "    \n",
    "    contrast = graycoprops(glcm, 'contrast').flatten()\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    energy = graycoprops(glcm, 'energy').flatten()\n",
    "    correlation = graycoprops(glcm, 'correlation').flatten()\n",
    "    \n",
    "    # Caractéristiques statistiques\n",
    "    mean = np.mean(resized)\n",
    "    std = np.std(resized)\n",
    "    \n",
    "    # Caractéristiques de Haralick avec Mahotas\n",
    "    haralick = mh.features.haralick(resized).mean(axis=0)\n",
    "    \n",
    "    # Caractéristiques LBP (Local Binary Pattern)\n",
    "    lbp = local_binary_pattern(resized, P=8, R=1, method='uniform')\n",
    "    hist_lbp, _ = np.histogram(lbp, bins=10, range=(0, 10))\n",
    "    hist_lbp = hist_lbp.astype(\"float\") / (hist_lbp.sum() + 1e-6)\n",
    "    \n",
    "    # Caractéristiques morphologiques\n",
    "    # Gradient\n",
    "    gradient = apply_morphological_operation(resized, 'gradient', 3)\n",
    "    mean_gradient = np.mean(gradient)\n",
    "    std_gradient = np.std(gradient)\n",
    "    \n",
    "    # Concatenation de toutes les caractéristiques\n",
    "    features = np.concatenate([\n",
    "        contrast, dissimilarity, homogeneity, energy, correlation,\n",
    "        [mean, std, mean_gradient, std_gradient],\n",
    "        haralick,\n",
    "        hist_lbp\n",
    "    ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebed6b5-15ce-4f40-b714-62079420e076",
   "metadata": {},
   "source": [
    "## Préparation du dataset et entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4297f-a69a-4fa8-8488-3508d136d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_dir, sample_limit=None):\n",
    "    \"\"\"\n",
    "    Prépare un jeu de données pour l'entraînement\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Répertoire contenant les images classées par dossiers\n",
    "        sample_limit: Limite du nombre d'échantillons par classe (None = tous)\n",
    "        \n",
    "    Returns:\n",
    "        X: Caractéristiques\n",
    "        y: Étiquettes de classe\n",
    "        class_names: Noms des classes\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    class_names = os.listdir(data_dir)\n",
    "    class_names = [c for c in class_names if os.path.isdir(os.path.join(data_dir, c))]\n",
    "    \n",
    "    print(f\"Classes trouvées: {class_names}\")\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        class_samples = glob.glob(os.path.join(class_path, \"*.jpg\"))\n",
    "        \n",
    "        if sample_limit:\n",
    "            class_samples = class_samples[:sample_limit]\n",
    "        \n",
    "        print(f\"Traitement de {len(class_samples)} images pour la classe '{class_name}'...\")\n",
    "        \n",
    "        for sample_path in tqdm(class_samples):\n",
    "            try:\n",
    "                # Charger l'image\n",
    "                img = cv2.imread(sample_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Extraire les caractéristiques\n",
    "                features = extract_texture_features(img)\n",
    "                \n",
    "                # Ajouter aux listes\n",
    "                X.append(features)\n",
    "                y.append(class_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors du traitement de {sample_path}: {e}\")\n",
    "    \n",
    "    return np.array(X), np.array(y), class_names\n",
    "\n",
    "def train_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entraîne un classifieur pour les types de terrain\n",
    "    \n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        \n",
    "    Returns:\n",
    "        Modèle entraîné\n",
    "    \"\"\"\n",
    "    # Création d'un pipeline avec normalisation et classification\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Paramètres pour la recherche par grille\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [50, 100],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5]\n",
    "    }\n",
    "    \n",
    "    # Recherche par grille avec validation croisée\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Meilleurs paramètres: {grid_search.best_params_}\")\n",
    "    print(f\"Meilleur score de validation croisée: {grid_search.best_score_:.4f}\")\n",
    "    print(\"Modèle entrainé.\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bc422-c5dc-4248-8c3d-c9e686b58b05",
   "metadata": {},
   "source": [
    "## Fonctions de visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e8cf5-82b0-4683-93ce-32e873f2edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_images(data_dir, n_samples=5):\n",
    "    \"\"\"\n",
    "    Visualise quelques exemples d'images pour chaque classe\n",
    "    \"\"\"\n",
    "    classes = os.listdir(data_dir)\n",
    "    classes = [c for c in classes if os.path.isdir(os.path.join(data_dir, c))]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(classes), n_samples, figsize=(15, 3*len(classes)))\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_samples = glob.glob(os.path.join(data_dir, class_name, '*.jpg'))\n",
    "        selected_samples = np.random.choice(class_samples, min(n_samples, len(class_samples)), replace=False)\n",
    "        \n",
    "        for j, sample in enumerate(selected_samples):\n",
    "            img = io.imread(sample)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].set_title(class_name)\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_morphological_operations(image, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Visualise les résultats de différentes opérations morphologiques\n",
    "    \"\"\"\n",
    "    operations = ['erosion', 'dilation', 'ouverture', 'fermeture', 'gradient', 'top-hat', 'black-hat']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Image originale\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        axes[0].imshow(image)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "        axes[0].imshow(gray, cmap='gray')\n",
    "    \n",
    "    axes[0].set_title('Image originale')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Appliquer et afficher les opérations\n",
    "    for i, operation in enumerate(operations):\n",
    "        result = apply_morphological_operation(image, operation, kernel_size)\n",
    "        axes[i+1].imshow(result, cmap='gray')\n",
    "        axes[i+1].set_title(f'{operation.capitalize()}, kernel={kernel_size}')\n",
    "        axes[i+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_segmentation(image, method='watershed'):\n",
    "    \"\"\"\n",
    "    Visualise le résultat de la segmentation\n",
    "    \"\"\"\n",
    "    # Segmenter l'image\n",
    "    labels, n_segments = segment_image_morphology(image, method=method)\n",
    "    \n",
    "    # Créer une image segmentée en couleur\n",
    "    if len(image.shape) == 2:\n",
    "        image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        image_color = image.copy()\n",
    "    \n",
    "    # Créer une version colorée des labels pour visualisation\n",
    "    label_viz = np.zeros_like(image_color)\n",
    "    \n",
    "    # Générer des couleurs aléatoires pour chaque label\n",
    "    np.random.seed(42)  # Pour la reproductibilité\n",
    "    colors = np.random.randint(0, 255, size=(n_segments + 2, 3), dtype=np.uint8)\n",
    "    colors[0] = [0, 0, 0]  # Fond en noir\n",
    "    \n",
    "    # Colorier les segments\n",
    "    for i in range(1, n_segments + 2):\n",
    "        label_viz[labels == i] = colors[i]\n",
    "    \n",
    "    # Afficher\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(image_color)\n",
    "    axes[0].set_title('Image originale')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(labels, cmap='jet')\n",
    "    axes[1].set_title(f'Labels ({n_segments} segments)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(label_viz)\n",
    "    axes[2].set_title('Segmentation colorée')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return labels, n_segments\n",
    "\n",
    "def visualize_gradient_types(image, kernel_size=3):\n",
    "    \"\"\"\n",
    "    Visualise les différents types de gradients morphologiques\n",
    "    \"\"\"\n",
    "    # Calculer les gradients\n",
    "    internal, external, morphological = calculate_gradient_morphology(image, kernel_size)\n",
    "    \n",
    "    # Afficher\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        axes[0].imshow(image)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "        axes[0].imshow(gray, cmap='gray')\n",
    "    \n",
    "    axes[0].set_title('Image originale')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(internal, cmap='gray')\n",
    "    axes[1].set_title('Gradient interne')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(external, cmap='gray')\n",
    "    axes[2].set_title('Gradient externe')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(morphological, cmap='gray')\n",
    "    axes[3].set_title('Gradient morphologique')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23826255-09d2-4850-b594-56891370bd66",
   "metadata": {},
   "source": [
    "## Fonctions pour la classification et la création de cartes de segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533fbdd7-fb2a-4c17-8939-e66d4e6f5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmentation_map(image, model, class_names):\n",
    "    \"\"\"\n",
    "    Crée une carte de segmentation avec classification des régions\n",
    "    \n",
    "    Args:\n",
    "        image: Image à analyser\n",
    "        model: Modèle de classification\n",
    "        class_names: Noms des classes\n",
    "    \"\"\"\n",
    "    # Segmentation de l'image\n",
    "    labels, n_segments = segment_image_morphology(image, method='watershed')\n",
    "    \n",
    "    # Classification de chaque segment\n",
    "    segment_classes = {}\n",
    "    \n",
    "    # Image segmentée pour la visualisation\n",
    "    segmented = np.zeros_like(image)\n",
    "    \n",
    "    # Si l'image est en niveaux de gris, la convertir en RGB\n",
    "    if len(image.shape) == 2:\n",
    "        image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        image_color = image.copy()\n",
    "    \n",
    "    # Couleurs pour chaque classe (à adapter selon vos classes spécifiques)\n",
    "    colors = {}\n",
    "    for i, name in enumerate(class_names):\n",
    "        hue = i * 180 // len(class_names)\n",
    "        # Convertir HSV en RGB pour générer des couleurs distinctes\n",
    "        rgb = cv2.cvtColor(np.uint8([[[hue, 255, 255]]]), cv2.COLOR_HSV2RGB)[0][0]\n",
    "        colors[name] = rgb.tolist()\n",
    "    \n",
    "    # Analyser chaque segment\n",
    "    for segment_id in range(1, n_segments + 2):\n",
    "        # Créer un masque pour le segment actuel\n",
    "        mask = (labels == segment_id)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "            \n",
    "        # Extraire la région correspondante de l'image originale\n",
    "        segment_img = image.copy()\n",
    "        if len(image.shape) == 3:\n",
    "            for c in range(3):\n",
    "                segment_img[:,:,c] = segment_img[:,:,c] * mask\n",
    "        else:\n",
    "            segment_img = segment_img * mask\n",
    "        \n",
    "        # Calculer les caractéristiques de texture\n",
    "        try:\n",
    "            features = extract_texture_features(segment_img)\n",
    "            \n",
    "            # Prédire la classe\n",
    "            predicted_class_idx = model.predict([features])[0]\n",
    "            predicted_class = class_names[predicted_class_idx]\n",
    "            \n",
    "            # Stocker la classe prédite\n",
    "            segment_classes[segment_id] = predicted_class\n",
    "            \n",
    "            # Colorier le segment\n",
    "            if predicted_class in colors:\n",
    "                if len(image.shape) == 3:\n",
    "                    for c in range(3):\n",
    "                        segmented[:,:,c][mask] = colors[predicted_class][c]\n",
    "                else:\n",
    "                    segmented[mask] = colors[predicted_class][0]  # Utiliser seulement le canal rouge\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la classification du segment {segment_id}: {e}\")\n",
    "    \n",
    "    # Créer une version blended (superposition semi-transparente)\n",
    "    alpha = 0.7\n",
    "    blended = cv2.addWeighted(image_color, 1 - alpha, segmented.astype(np.uint8), alpha, 0)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(image_color)\n",
    "    axes[0].set_title('Image originale')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(segmented)\n",
    "    axes[1].set_title('Classification des segments')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(blended)\n",
    "    axes[2].set_title('Superposition')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Ajouter une légende\n",
    "    patches = []\n",
    "    for class_name in class_names:\n",
    "        if class_name in colors:\n",
    "            color_rgb = np.array(colors[class_name]) / 255.0\n",
    "            patch = plt.Rectangle((0, 0), 1, 1, fc=color_rgb)\n",
    "            patches.append(patch)\n",
    "    \n",
    "    fig.legend(patches, class_names, loc='lower center', ncol=len(class_names), bbox_to_anchor=(0.5, -0.05))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyser la distribution des types de terrain\n",
    "    class_counts = {}\n",
    "    for class_name in segment_classes.values():\n",
    "        if class_name in class_counts:\n",
    "            class_counts[class_name] += 1\n",
    "        else:\n",
    "            class_counts[class_name] = 1\n",
    "    \n",
    "    # Afficher la distribution sous forme de diagramme circulaire\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(list(class_counts.values()), labels=list(class_counts.keys()), autopct='%1.1f%%')\n",
    "    plt.title('Distribution des types de terrain')\n",
    "    plt.show()\n",
    "    \n",
    "    return segmented, segment_classes, blended\n",
    "\n",
    "def compare_segmentation_methods(image):\n",
    "    \"\"\"\n",
    "    Compare différentes méthodes de segmentation\n",
    "    \n",
    "    Args:\n",
    "        image: Image à segmenter\n",
    "    \"\"\"\n",
    "    methods = ['watershed', 'region_growing']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(methods) + 1, figsize=(5 * (len(methods) + 1), 5))\n",
    "    \n",
    "    # Image originale\n",
    "    if len(image.shape) == 2:\n",
    "        axes[0].imshow(image, cmap='gray')\n",
    "    else:\n",
    "        axes[0].imshow(image)\n",
    "    axes[0].set_title('Image originale')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Résultats des différentes méthodes\n",
    "    for i, method in enumerate(methods):\n",
    "        labels, n_segments = segment_image_morphology(image, method=method)\n",
    "        \n",
    "        # Afficher les labels en couleurs\n",
    "        axes[i + 1].imshow(labels, cmap='jet')\n",
    "        axes[i + 1].set_title(f'Méthode: {method}\\n{n_segments} segments')\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c160f-6cc9-4f25-81ea-4c9da24ebd16",
   "metadata": {},
   "source": [
    "## Exécution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee6f4e-d236-410a-a522-1cbac43b484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration du dataset\n",
    "data_path = \"data\"  # Ajustez si votre dossier a un nom différent\n",
    "visualize_sample_images(data_path)\n",
    "\n",
    "# Préparation des données - limiter le nombre d'échantillons pour un premier test\n",
    "X, y, class_names = prepare_dataset(data_path, sample_limit=50)\n",
    "\n",
    "print(f\"Caractéristiques extraites: {X.shape}\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = train_classifier(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Précision sur l'ensemble de test: {accuracy:.4f}\")\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "joblib.dump(model, 'terrain_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44a6fe-c00e-4403-abab-aceaa92fb8ca",
   "metadata": {},
   "source": [
    "## Tests et démonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1b3eb-a2a4-4f9d-915e-afe0429f96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle (s'il a été sauvegardé précédemment)\n",
    "try:\n",
    "    model = joblib.load('terrain_classifier_model.pkl')\n",
    "except:\n",
    "    print(\"Modèle non trouvé. Veuillez d'abord entraîner le modèle.\")\n",
    "\n",
    "# Sélectionner quelques images de test\n",
    "test_images = []\n",
    "for class_name in class_names:\n",
    "    class_samples = glob.glob(os.path.join(data_path, class_name, '*.jpg'))\n",
    "    if class_samples:\n",
    "        test_images.append(class_samples[0])\n",
    "\n",
    "# Tester le système sur les images sélectionnées\n",
    "for test_image in test_images[:3]:  # Tester les 3 premières images\n",
    "    print(f\"\\nTest sur l'image: {test_image}\")\n",
    "    image = cv2.imread(test_image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title('Image de test')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualiser les opérations morphologiques\n",
    "    visualize_morphological_operations(image)\n",
    "    \n",
    "    # Visualiser les gradients morphologiques\n",
    "    visualize_gradient_types(image)\n",
    "    \n",
    "    # Comparer les méthodes de segmentation\n",
    "    compare_segmentation_methods(image)\n",
    "    \n",
    "    # Créer une carte de segmentation avec classification\n",
    "    segmented, segment_classes, blended = create_segmentation_map(image, model, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0ce94-09d4-4869-b352-a9ce0835912d",
   "metadata": {},
   "source": [
    "## Evaluation de la ségmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ab4b7-3b6b-4516-a184-1004289fd52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_segmentation_methods(images, methods=['watershed', 'region_growing']):\n",
    "    \"\"\"\n",
    "    Évalue les performances des différentes méthodes de segmentation\n",
    "    \n",
    "    Args:\n",
    "        images: Liste de chemins d'images à évaluer\n",
    "        methods: Liste des méthodes à comparer\n",
    "    \"\"\"\n",
    "    results = {method: {'n_segments': [], 'segments_median_size': []} for method in methods}\n",
    "    \n",
    "    for img_path in images:\n",
    "        print(f\"Évaluation de {img_path}\")\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        for method in methods:\n",
    "            # Mesurer le temps d'exécution\n",
    "            start_time = time.time()\n",
    "            labels, n_segments = segment_image_morphology(img, method=method)\n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            # Calculer la taille médiane des segments\n",
    "            segment_sizes = []\n",
    "            for i in range(1, n_segments + 2):\n",
    "                segment_size = np.sum(labels == i)\n",
    "                if segment_size > 0:\n",
    "                    segment_sizes.append(segment_size)\n",
    "            \n",
    "            median_size = np.median(segment_sizes) if segment_sizes else 0\n",
    "            \n",
    "            # Stocker les résultats\n",
    "            results[method]['n_segments'].append(n_segments)\n",
    "            results[method]['segments_median_size'].append(median_size)\n",
    "            \n",
    "            print(f\"  Méthode {method}: {n_segments} segments, taille médiane = {median_size:.1f} pixels\")\n",
    "    \n",
    "    # Calculer les statistiques\n",
    "    for method in methods:\n",
    "        avg_segments = np.mean(results[method]['n_segments'])\n",
    "        avg_size = np.mean(results[method]['segments_median_size'])\n",
    "        print(f\"\\nStatistiques pour {method}:\")\n",
    "        print(f\"  Nombre moyen de segments: {avg_segments:.1f}\")\n",
    "        print(f\"  Taille médiane moyenne des segments: {avg_size:.1f} pixels\")\n",
    "    \n",
    "    # Visualiser les résultats\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Diagramme à barres pour le nombre de segments\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.bar(np.arange(len(images)) + i*0.35, results[method]['n_segments'], width=0.35, \n",
    "                label=method, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Images')\n",
    "    plt.ylabel('Nombre de segments')\n",
    "    plt.title('Nombre de segments par méthode')\n",
    "    plt.legend()\n",
    "    plt.xticks(np.arange(len(images)), [os.path.basename(img) for img in images], rotation=45)\n",
    "    \n",
    "    # Diagramme à barres pour la taille médiane des segments\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, method in enumerate(methods):\n",
    "        plt.bar(np.arange(len(images)) + i*0.35, results[method]['segments_median_size'], width=0.35, \n",
    "                label=method, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Images')\n",
    "    plt.ylabel('Taille médiane des segments (pixels)')\n",
    "    plt.title('Taille médiane des segments par méthode')\n",
    "    plt.legend()\n",
    "    plt.xticks(np.arange(len(images)), [os.path.basename(img) for img in images], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e2426-525a-4fcf-801a-627631009bca",
   "metadata": {},
   "source": [
    "## Analyse des textures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b47e4-fe31-4a78-989a-8f64bfccb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_texture_features(image):\n",
    "    \"\"\"\n",
    "    Analyse les caractéristiques de texture d'une image et les visualise\n",
    "    \n",
    "    Args:\n",
    "        image: Image à analyser\n",
    "    \"\"\"\n",
    "    # Extraire les caractéristiques\n",
    "    features = extract_texture_features(image)\n",
    "    \n",
    "    # Convertir en niveaux de gris si nécessaire\n",
    "    if len(image.shape) > 2:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Calculer les matrices GLCM\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    glcm = graycomatrix(gray, distances, angles, 256, symmetric=True, normed=True)\n",
    "    \n",
    "    # Calculer les propriétés GLCM pour visualisation\n",
    "    contrast = graycoprops(glcm, 'contrast')\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')\n",
    "    energy = graycoprops(glcm, 'energy')\n",
    "    correlation = graycoprops(glcm, 'correlation')\n",
    "    \n",
    "    # Calculer LBP\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    \n",
    "    # Visualiser\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Image originale\n",
    "    axes[0, 0].imshow(image if len(image.shape) > 2 else gray, cmap='gray' if len(image.shape) == 2 else None)\n",
    "    axes[0, 0].set_title('Image originale')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # LBP\n",
    "    axes[0, 1].imshow(lbp, cmap='gray')\n",
    "    axes[0, 1].set_title('Local Binary Pattern')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Histogramme LBP\n",
    "    hist_lbp, _ = np.histogram(lbp, bins=10, range=(0, 10))\n",
    "    hist_lbp = hist_lbp.astype(\"float\") / (hist_lbp.sum() + 1e-6)\n",
    "    axes[0, 2].bar(range(10), hist_lbp)\n",
    "    axes[0, 2].set_title('Histogramme LBP')\n",
    "    axes[0, 2].set_xlabel('Bins')\n",
    "    axes[0, 2].set_ylabel('Fréquence normalisée')\n",
    "    \n",
    "    # Propriétés GLCM en fonction de la distance\n",
    "    x = distances\n",
    "    axes[1, 0].plot(x, contrast.mean(axis=1), 'o-', label='Contraste')\n",
    "    axes[1, 0].plot(x, dissimilarity.mean(axis=1), 's-', label='Dissimilarité')\n",
    "    axes[1, 0].plot(x, homogeneity.mean(axis=1), '^-', label='Homogénéité')\n",
    "    axes[1, 0].set_title('Propriétés GLCM vs Distance')\n",
    "    axes[1, 0].set_xlabel('Distance')\n",
    "    axes[1, 0].set_ylabel('Valeur')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Propriétés GLCM en fonction de l'angle\n",
    "    x = [0, 45, 90, 135]  # Angles en degrés pour l'affichage\n",
    "    axes[1, 1].plot(x, contrast.mean(axis=0), 'o-', label='Contraste')\n",
    "    axes[1, 1].plot(x, dissimilarity.mean(axis=0), 's-', label='Dissimilarité')\n",
    "    axes[1, 1].plot(x, homogeneity.mean(axis=0), '^-', label='Homogénéité')\n",
    "    axes[1, 1].set_title('Propriétés GLCM vs Angle')\n",
    "    axes[1, 1].set_xlabel('Angle (degrés)')\n",
    "    axes[1, 1].set_ylabel('Valeur')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    # Caractéristiques d'Haralick\n",
    "    haralick = mh.features.haralick(gray).mean(axis=0)\n",
    "    axes[1, 2].bar(range(len(haralick)), haralick)\n",
    "    axes[1, 2].set_title('Caractéristiques de Haralick')\n",
    "    axes[1, 2].set_xlabel('Index de caractéristique')\n",
    "    axes[1, 2].set_ylabel('Valeur')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca9528-3dab-4b86-8131-87c06a6f4750",
   "metadata": {},
   "source": [
    "## Importance des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf56af-193d-47d9-95d1-e18db6f64355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, feature_names=None):\n",
    "    \"\"\"\n",
    "    Analyse et visualise l'importance des caractéristiques du modèle RandomForest\n",
    "    \n",
    "    Args:\n",
    "        model: Modèle entraîné (avec RandomForestClassifier)\n",
    "        feature_names: Noms des caractéristiques (optionnel)\n",
    "    \"\"\"\n",
    "    # Vérifier si le modèle est un pipeline\n",
    "    if hasattr(model, 'named_steps') and 'classifier' in model.named_steps:\n",
    "        classifier = model.named_steps['classifier']\n",
    "    else:\n",
    "        classifier = model\n",
    "    \n",
    "    # Vérifier si c'est un RandomForest\n",
    "    if not hasattr(classifier, 'feature_importances_'):\n",
    "        print(\"Le modèle n'est pas un RandomForest ou n'a pas d'attribut 'feature_importances_'\")\n",
    "        return\n",
    "    \n",
    "    # Obtenir l'importance des caractéristiques\n",
    "    importances = classifier.feature_importances_\n",
    "    \n",
    "    # Créer des noms de caractéristiques par défaut si non spécifiés\n",
    "    if feature_names is None:\n",
    "        # Caractéristiques GLCM\n",
    "        glcm_props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']\n",
    "        distances = [1, 2, 3]\n",
    "        angles = [0, 45, 90, 135]\n",
    "        glcm_features = [f\"{prop}_d{d}_a{a}\" for prop in glcm_props \n",
    "                         for d in distances for a in angles]\n",
    "        \n",
    "        # Caractéristiques statistiques\n",
    "        stat_features = ['mean', 'std', 'mean_gradient', 'std_gradient']\n",
    "        \n",
    "        # Caractéristiques Haralick (13 caractéristiques)\n",
    "        haralick_features = [f'haralick_{i}' for i in range(13)]\n",
    "        \n",
    "        # Caractéristiques LBP (10 bins d'histogramme)\n",
    "        lbp_features = [f'lbp_bin_{i}' for i in range(10)]\n",
    "        \n",
    "        feature_names = glcm_features + stat_features + haralick_features + lbp_features\n",
    "    \n",
    "    # Trier les caractéristiques par importance\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Visualiser l'importance des caractéristiques\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Montrer les 20 caractéristiques les plus importantes\n",
    "    n_features = min(20, len(importances))\n",
    "    plt.barh(range(n_features), importances[indices[:n_features]], align='center')\n",
    "    plt.yticks(range(n_features), [feature_names[i] for i in indices[:n_features]])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Caractéristique')\n",
    "    plt.title('Importance des caractéristiques')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Retourner les importances triées\n",
    "    top_features = [(feature_names[i], importances[i]) for i in indices[:n_features]]\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ce0d8-9a67-47a7-9123-55c62aaf261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_satellite_image(image_path, model, class_names):\n",
    "    \"\"\"\n",
    "    Effectue une analyse complète d'une image satellite\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image à analyser\n",
    "        model: Modèle de classification entraîné\n",
    "        class_names: Noms des classes\n",
    "    \"\"\"\n",
    "    print(f\"Analyse de l'image: {image_path}\")\n",
    "    \n",
    "    # Charger et prétraiter l'image\n",
    "    image = load_and_process_image(image_path)\n",
    "    \n",
    "    # Afficher l'image originale\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title('Image satellite')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # 1. Appliquer et visualiser les opérations morphologiques\n",
    "    print(\"\\n1. Opérations morphologiques\")\n",
    "    visualize_morphological_operations(image)\n",
    "    \n",
    "    # 2. Analyser les gradients morphologiques\n",
    "    print(\"\\n2. Gradients morphologiques\")\n",
    "    visualize_gradient_types(image)\n",
    "    \n",
    "    # 3. Comparer les méthodes de segmentation\n",
    "    print(\"\\n3. Comparaison des méthodes de segmentation\")\n",
    "    compare_segmentation_methods(image)\n",
    "    \n",
    "    # 4. Analyser les caractéristiques de texture\n",
    "    print(\"\\n4. Analyse des textures\")\n",
    "    features = analyze_texture_features(image)\n",
    "    \n",
    "    # 5. Créer une carte de segmentation avec classification\n",
    "    print(\"\\n5. Segmentation et classification\")\n",
    "    segmented, segment_classes, blended = create_segmentation_map(image, model, class_names)\n",
    "    \n",
    "    # 6. Afficher un résumé des résultats\n",
    "    print(\"\\n6. Résumé des résultats\")\n",
    "    class_distribution = {}\n",
    "    for class_name in segment_classes.values():\n",
    "        if class_name in class_distribution:\n",
    "            class_distribution[class_name] += 1\n",
    "        else:\n",
    "            class_distribution[class_name] = 1\n",
    "    \n",
    "    print(\"Distribution des types de terrain:\")\n",
    "    for class_name, count in class_distribution.items():\n",
    "        percentage = count / len(segment_classes) * 100\n",
    "        print(f\"  {class_name}: {count} segments ({percentage:.1f}%)\")\n",
    "    \n",
    "    return segmented, segment_classes, blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77539da3-0ab5-4c1c-b8c3-2ccfba591fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_image(image_path):\n",
    "    \"\"\"\n",
    "    Charge et prétraite une image pour l'analyse\n",
    "    \n",
    "    Args:\n",
    "        image_path: Chemin vers l'image à charger\n",
    "        \n",
    "    Returns:\n",
    "        Image prétraitée\n",
    "    \"\"\"\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Redimensionner si l'image est trop grande\n",
    "    max_dim = 1024\n",
    "    h, w = image.shape[:2]\n",
    "    if max(h, w) > max_dim:\n",
    "        if h > w:\n",
    "            new_h, new_w = max_dim, int(w * max_dim / h)\n",
    "        else:\n",
    "            new_h, new_w = int(h * max_dim / w), max_dim\n",
    "        image = cv2.resize(image, (new_w, new_h))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87684c98-b418-4559-9daa-71605bde40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale pour exécuter l'analyse d'images satellitaires\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Définir le chemin vers les données\n",
    "    data_path = \"data\"  # Ajustez selon votre configuration\n",
    "    \n",
    "    print(\"ANALYSE DE TEXTURES ET SEGMENTATION D'IMAGES SATELLITAIRES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Explorer le dataset\n",
    "    print(\"\\n1. Exploration du dataset\")\n",
    "    visualize_sample_images(data_path)\n",
    "    \n",
    "    # 2. Extraire les caractéristiques et entraîner le modèle\n",
    "    print(\"\\n2. Extraction des caractéristiques et entraînement du modèle\")\n",
    "    \n",
    "    # Vérifier si un modèle préentraîné existe\n",
    "    model_path = 'terrain_classifier_model.pkl'\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Chargement du modèle préentraîné...\")\n",
    "        model = joblib.load(model_path)\n",
    "        \n",
    "        # Récupérer les noms de classes depuis le dossier de données\n",
    "        class_names = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "        print(f\"Classes détectées: {class_names}\")\n",
    "    else:\n",
    "        print(\"Entraînement d'un nouveau modèle...\")\n",
    "        # Limiter le nombre d'échantillons pour un entraînement plus rapide\n",
    "        X, y, class_names = prepare_dataset(data_path, sample_limit=100)\n",
    "        \n",
    "        # Division en ensembles d'entraînement et de test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        \n",
    "        # Entraînement du modèle\n",
    "        model = train_classifier(X_train, y_train)\n",
    "        \n",
    "        # Évaluation du modèle\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Précision sur l'ensemble de test: {accuracy:.4f}\")\n",
    "        print(\"\\nRapport de classification:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "        \n",
    "        # Sauvegarder le modèle\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"Modèle sauvegardé dans {model_path}\")\n",
    "    \n",
    "    # 3. Analyser l'importance des caractéristiques\n",
    "    print(\"\\n3. Analyse de l'importance des caractéristiques\")\n",
    "    top_features = analyze_feature_importance(model)\n",
    "    \n",
    "    # 4. Sélectionner des images de test et les analyser\n",
    "    print(\"\\n4. Analyse d'images de test\")\n",
    "    \n",
    "    # Sélectionner une image par classe\n",
    "    test_images = []\n",
    "    for class_name in class_names:\n",
    "        class_samples = glob.glob(os.path.join(data_path, class_name, '*.jpg'))\n",
    "        if class_samples:\n",
    "            test_images.append(class_samples[0])\n",
    "    \n",
    "    # Analyser chaque image de test\n",
    "    for test_image in test_images[:2]:  # Limiter à 2 images pour la démo\n",
    "        analyze_satellite_image(test_image, model, class_names)\n",
    "    \n",
    "    # 5. Comparer les méthodes de segmentation\n",
    "    print(\"\\n5. Comparaison des méthodes de segmentation\")\n",
    "    segmentation_results = evaluate_segmentation_methods(test_images[:2])\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    print(f\"\\nAnalyse terminée en {execution_time:.1f} secondes\")\n",
    "\n",
    "# Exécuter la fonction principale\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f6015-8439-4134-ac01-b6a807220134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
